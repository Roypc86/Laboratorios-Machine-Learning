# -*- coding: utf-8 -*-
"""Laboratorio5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vq7NlpI4J6wr7EDSUEhnplS6YUYYJJ46

## `Laboratorio #5`
### Estudiante: Roy Esteban Padilla Calderón
### Carné: B85854

#### `Paso 1. Carga de los datos:`
"""

# Código preveído por el profesor Pablo Sauma Chacón

import matplotlib.pyplot as plt
import numpy as np
import pickle
import torch

# Custom subdirectory to find images
DIRECTORY = "images"

def load_data():
    def unpickle(file):
        with open(file, 'rb') as fo:
            dict = pickle.load(fo, encoding='bytes')
        return dict
    names = [n.decode('utf-8') for n in unpickle(DIRECTORY+"/batches.meta")[b'label_names']]
    x_train = None
    y_train = []
    for i in range(1,6):
        data = unpickle(DIRECTORY+"/data_batch_"+str(i))
        if i>1:
            x_train = np.append(x_train, data[b'data'], axis=0)
        else:
            x_train = data[b'data']
        y_train += data[b'labels']
    data = unpickle(DIRECTORY+"/test_batch")
    x_test = data[b'data']
    y_test = data[b'labels']
    return names,x_train,y_train,x_test,y_test

names,x_train,y_train,x_test,y_test = load_data()

def plot_tensor(tensor, perm=None):
    if perm==None: perm = (1,2,0)
    plt.figure()
    plt.imshow(tensor.permute(perm).numpy().astype(np.uint8))
    plt.show()

"""Comprobación de núcleos CUDA"""

torch.cuda.is_available() # Checkeo de disponibilidad de CUDA
torch.cuda.empty_cache() # Limpieza de la caché

"""### `Paso 2. Procesamiento de los datos:`

Note que los datos de las imágenes vienen como un arreglo de datos (tipo uint8) de tamaño 50000x3096, donde cada fila corresponde a una imagen y los 3096 valores corresponden a una imagen de 3x32x32 (los primeros 1024 valores corresponden a la imagen 32x32 del canal rojo, los siguientes 1024 al 32x32 del verde, y por último los 1024 del canal azul). Los labels corresponden a un arreglo de enteros tamaño 50000. En ambos casos deberá convertir los datos a tensores, y en el caso de las imágenes cambiar su forma de 50000x3096 a 50000x3x32x32 (note que el orden de los datos  permanece igual, esto porque las capas convolucionales prefieren que los canales vengan como dimensión superior: CxHxW en lugar del habitual HxWxC; esto por motivos de eficiencia).
"""

COLOR_DIM = 3 # Número de filtros iniciales 3 por ser RGB
IMAGE_DIM = 32 # Dimensiones de la imagen
CLASSIFICATIONS = np.unique(y_train).size # Cantidad de clasificaciones

# Conversión de numpy a tensores
x_train_processed = torch.tensor(np.reshape(x_train, (x_train.shape[0], COLOR_DIM, IMAGE_DIM, IMAGE_DIM)), dtype= torch.float)
x_test_processed = torch.tensor(np.reshape(x_test, (x_test.shape[0], COLOR_DIM, IMAGE_DIM, IMAGE_DIM)), dtype= torch.float)
y_train_processed = torch.tensor(y_train)
y_test_processed = torch.tensor(y_test)

"""`Valor de y con su correspondiente a la categoría`

| y_value| Name |
|--|--|
| 0| avión|
| 1| automóvil |
| 2| pájaro |
| 3| gato |
| 4| perro |
| 5| venado |
| 6| rana |
| 7| caballo |
| 8| barco |
| 9| camión |
"""

DICT_Y = {
    0 : 'avion', 1: 'automovil', 2: 'pajaro', 3: 'gato', 4 : 'perro' , 5 : 'venado' ,
    6: 'rana',  7: 'caballo' , 8: 'barco', 9: 'camion'
}

plot_tensor(x_train_processed[0])
print(y_train[0])
np.unique(y_train)

"""### `Paso 3. Construcción de la red neuronal:`


"""

from torch import nn
from torch import flatten

class ConvNN(nn.Module):
    def __init__(self):
        super().__init__()
        
        # Primera convolución
        # Entra una imagen 3x32x32
        self.conv1 =  nn.Conv2d(in_channels = COLOR_DIM, out_channels = 10, kernel_size = (5,5), stride=1, padding= 'same')
        # Sale una imagen de 10x32x32
        self.relu1 = nn.ReLU()
        self.maxpool1 = nn.MaxPool2d(2)
        # Imagen de 10x16x16

        # Segunda convolución 
        # Entra una imagen de 10x16x16
        self.conv2 =  nn.Conv2d(in_channels = 10, out_channels = 30, kernel_size = (5,5), stride=1, padding= 'same')
        # Sale una imagen de 30x16x16
        self.relu2 = nn.ReLU()
        self.maxpool2 = nn.MaxPool2d(2)
        # Sale una imagen de 30x8x8 => vector de 1920

        # Tercera convolución 
        # Entra una imagen de 30x8x8 
        self.conv3 =  nn.Conv2d(in_channels = 30, out_channels = 50, kernel_size = (5,5), stride=1, padding= 'same')
        # Sale una imagen de 50x8x8
        self.relu3 = nn.ReLU()
        self.maxpool3 = nn.MaxPool2d(2)
        # Sale una imagen de 50x4x4 => vector de 800

        # Red neuronal
        self.fc1 = nn.Linear(800, 500)
        self.act1 = nn.ReLU()
        self.fc2 = nn.Linear(500, CLASSIFICATIONS)
        self.act2 = nn.Sigmoid() # Se utiliza sigmoide porque CrossEntropy realiza una acción similar a la softmax, además, da mejores resultados
        
    def forward(self, x):
        ''' Sobre escritura del método de forward propagation, aplicando las capas convolucionales
            y luego las capas densas de la red neuronal'''
        # aplicación de la primera convolución
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.maxpool1(x)

        # aplicación de la segunda convolución
        x = self.conv2(x)
        x = self.relu2(x)
        x = self.maxpool2(x)

        # salida de 10x5x5
        # aplicación de la tercera convolución
        x = self.conv3(x)
        x = self.relu3(x)
        x = self.maxpool3(x)

        # aplanamiento de los datos
        x = flatten(x, 1)

        # Ejecución en la red neuroral
        h = self.act1( self.fc1(x) )
        out = self.act2( self.fc2(h) )
        
        return out

    def get_general_precision(self, y_predict, y_true):
        '''Método de obtención de la exactitud del modelo'''
        corrects = 0
        for index, value in enumerate(y_predict):
            corrects += 1 if torch.argmax(value) == y_true[index] else 0
        return (corrects/y_true.shape[0])*100
  
    def get_confusion_matrix(self, y_predict, y_true):
        '''Método para calcular la matriz de confusión siendo las filas los valores pedichos y las columnas los reales'''
        confusion_matrix  = np.zeros((y_predict[0].shape[0], y_predict[0].shape[0]))
        for index in range(y_true.shape[0]):
            confusion_matrix[torch.argmax(y_predict[index])][y_true[index]] += 1
        
        return confusion_matrix
    
    def get_specific_precision(self, confusion_matrix):
        '''Método para obtener las precisiones del modelo en cada una de las categorías'''
        precisions = {}
        for key in DICT_Y.keys():
            precisions[DICT_Y[key]] = confusion_matrix[key][key] /(np.sum(confusion_matrix[key]) if np.sum(confusion_matrix[key]) != 0 else 1)*100
        return precisions

    def printTable(self,labels, matrix):
        # Impresión de la matriz de forma bonita
        format_row = "{:>9}" * (len(labels) + 1)
        print(format_row.format("", *labels))
        for _class, row in zip(labels, matrix):
            print(format_row.format(_class, *row))

"""`Entrenamiento de la red neuronal:`"""

device = torch.device("cuda:0")

LEARNING_RATE = 0.0007
model = ConvNN()
loss_func = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

print(x_train_processed.shape, len(y_train))
# Carga a la GPU
x_train_processed = x_train_processed.to(device)
y_train_processed = y_train_processed.to(device)
x_test_processed = x_test_processed.to(device)
y_test_processed = y_test_processed.to(device)
model = model.to(device)

torch.cuda.empty_cache()

# Entrenamiento
loss_train = []
corrects = []
EPOCHS = 300

print(x_train_processed.is_cuda)
for i in range(EPOCHS):
    model.train()
    optimizer.zero_grad()
    y_pred = model(x_train_processed)
    loss = loss_func(y_pred, y_train_processed)
    loss.backward()
    optimizer.step()
    loss_train.append(loss.item())
    corrects.append(model.get_general_precision(y_pred,y_train_processed))
    print('EPOCH: ', i, 'accuracy : ', corrects[-1])
    torch.cuda.empty_cache()

# Impresión de gráficos y resultados del modelo
len_ = len(loss_train)
xpoints = np.linspace(0, len_, num = len_)
plt.plot(xpoints, loss_train)
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title(("Pérdida con el learning rate: " + str(LEARNING_RATE)))
plt.show()

plt.plot(xpoints, corrects)
plt.xlabel("Epochs")
plt.ylabel("Corrects")
plt.title(("Porcentaje de exactitud en general con el learning rate: " + str(LEARNING_RATE)))
plt.show()
print("last correct value:", corrects[-1])

confusion_matrix = model.get_confusion_matrix(model(x_train_processed), y_train_processed)
model.printTable(DICT_Y.values(), confusion_matrix)
model.get_specific_precision(confusion_matrix)

"""`Evaluación del modelo con el dataset de testing:`"""

loss_train = []
loss_test = []
corrects = []

for i in range(EPOCHS):
    # Entrenamiento
    model.train()
    optimizer.zero_grad()
    y_pred = model( x_train_processed )
    loss = loss_func(y_pred, y_train_processed)
    loss.backward()
    optimizer.step()
    # Evaluación
    model.eval()
    with torch.no_grad(): # Apaga el cálculo de gradientes
        loss2 = loss_func( model(x_test_processed), y_test_processed)
    loss_train.append(loss.item())
    loss_test.append(loss2.item())
    corrects.append(model.get_general_precision(y_pred, y_train_processed))

# Impresión de gráficos y resultados del modelo
len_ = len(loss_train)
xpoints = np.linspace(0, len_, num = len_)
plt.plot(xpoints, loss_train, color = 'red')
plt.plot(xpoints, loss_test, color = 'blue')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title(("Pérdida con el learning rate: " + str(LEARNING_RATE)))
plt.show()

plt.plot(xpoints, corrects)
plt.xlabel("Epochs")
plt.ylabel("Corrects")
plt.title(("Porcentaje de exactitud en general con el learning rate: " + str(LEARNING_RATE)))
plt.show()
print("last correct value:", corrects[-1])

confusion_matrix = model.get_confusion_matrix(model(x_test_processed), y_test_processed)
model.printTable(DICT_Y.values(), confusion_matrix)
model.get_specific_precision(confusion_matrix)

"""`Guardado del modelo:`"""

model_filename = 'modelo-{}-{}'.format(EPOCHS, LEARNING_RATE)

torch.save({
    'model_state': model.state_dict(),
    'opt_state': optimizer.state_dict(),
    'epoch' : EPOCHS
}, model_filename)

"""### `Paso 8. Respuestas y análisis: `

Si se encuentra satisfecho con su red, entonces grafique la matriz de confusión para las diferentes categorías. 

¿Cuáles categorías confunde su red? ¿Por qué cree que esas categorías le generan confusión/errores de clasificación?

En el laboratorio se notó que al utilizar en la capa de salida la función `Sigmoide` se obtienen mejores resultados y además permite tasas de aprendizaje más elevadas, con lo cual se utilizó esta para la elaboración de la red neural.

Entorno al proceso de testeo y entrenamiento se puede observar que conforme avanzan las épocas el modelo en general mejora bastante su comportamiento. Como se observa en el gráfico de pérdida del testing este valor tiende a disminuir conforme avanzan las épocas en el entrenamiento (línea color rojo) mas no en el testing (línea color azul), lo cual indica que el sistema puede estarse sobreajustando, por otra parte, en el gráfico de accuracy o exactitud de testing se observa que dicho valor aumenta con cada iteración, por lo que con estos gráficos se nota que el modelo realmente mejora y tiende a mejorar conforme avanzan la épocas y se aplican las técnicas de desenso del gradiente y demás para mejorarlo.

Con respecto al comportamiento en las categorías se nota que en general la exactitud del modelo es buena, alcanzando así una de `74.8%` lo cual es bastante aceptable. Ahora, de manera más específica, como se nota en la matriz de confusión y posteriormente en las impresiones de las precisiones, el modelo tiene un mejor comportamiento al clasificar los vehículos mas no es así con los animales, donde se obtienen valores más bajos. De forma más detallada se observa un comportamiento donde entre los mismos vehículos la red se confunde, y hay más errores prediciendo que sea automóvil, avión, barco y camión cuando el valor real pertenece a estas mismas categorías, por lo que se esperaría que si se está prediciendo una imagen que es algún vehículo la red si falla lo más probable es que su respuesta sea otro vehículo. Este comportamiento también se ve dentro de los animales, donde la red se confunde entre ellos teniendo mayor cantidad de errores al predecir otro animal que un vehículo. 

En conclusión la red tiene un mejor comportamiento al clasificar imágenes de vehículos que las de animales, esto puede ser porque los vehículos tienen formas o contornos más generales y sencillos de distinguir, sin embargo, esto no sucede así con los animales donde estos pueden tener características más específicas que los diferencien, por ejemplo la red cuando predijo gato erró al confundirlo en multiples ocasiones con un venado. 

En general, desde mi punto de vista la red tiene un buen comportamiento a pesar de que las imágenes sean de un tamaño muy comedido causando que no se observen en tanto detalle características más específicas, con lo cual, se esperaría que si se utilizaran imágenes de más resolución se tenga un mejor comportamiento aunque el procesamiento sea más lento. Como aspectos a mejorar están realizar más pruebas variando el tamaño del kernel y los filtros que se generan en cada una de las convoluciones, ya que considero que el modelo es bastante pesado y puede mejorarse para ser más eficiente conservando los resultados o bien superándolos.
"""