# -*- coding: utf-8 -*-
"""laboratorio3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G4JKBrK7X9BztSUUU-13aMHZNStGORsL

# `Laboratorio 3`
Estudiante: Roy Esteban Padilla Calderón.

Carné: B85854.
"""

# Imports de bibliotecas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Lectura del archivo
df = pd.read_csv('fish_perch.csv')
target_value = 'Weight'
target_column = df[target_value]
df = df.drop(columns= [target_value])
target_column

"""# 1. `Función MSE(y_true, y_predict)` y `Función MAE(y_true, y_predict)` 
Recibe dos objetos pd.Series que contienen los valores reales de un conjunto de datos y los valores estimados por un modelo. 
"""

def MSE(y_true: pd.Series, y_predict: pd.Series):
    return ((y_true - y_predict)**2).sum()/y_true.size

def MAE(y_true: pd.Series, y_predict: pd.Series):
    return (y_true - y_predict).sum()/y_true.size

"""# 2. `Función score(y_true, y_predict)` 
Recibe dos objetos pd.Series que contienen los valores reales de un conjunto de datos y los valores estimados por un modelo. Calcule y retorne el coeficiente de determinación (R2) de dicha predicción.
"""

def score(y_true : pd.Series, y_predict:pd.Series):
    rss = ((y_true - y_predict)**2).sum()
    tss = ((y_true - y_true.mean())**2).sum()
    return 1-(rss/tss)

"""# 3. `Clase LinearRegression`

Método fit(self, x, y, max_epochs=100, threshold=0.01, learning_rate=0.001, momentum=0, decay=0, error=’mse’, regularization=’none’, lambda=0)
Encargado de ajustar los cj para obtener así el modelo.

# 4. `Método predict(self, x)` 
que recibe un objeto pandas.DataFrame x que
contiene los datos para los que se desea hacer su estimación. El método debe
retornar un objeto de tipo pd.Series con los valores estimados para cada uno de
los valores.

a. Este método será llamado después de fit, punto en el cuál ya debería
contarse con los valores de C/los pesos necesarios para hacer la estimación.

"""

import sys
class LinearRegression:
    def __init__(self):
        self.c_values = None

    def predict(self, x : pd.Series):
        if not "bias" in x.columns:
            x.insert(0, "bias", np.ones(x.shape[0]))
        x_numpy = x.to_numpy()
        return pd.Series(np.matmul( x_numpy, self.c_values), x.index)

    def fit(self, x : pd.DataFrame, y : pd.Series, max_epochs=100, threshold=0.01, learning_rate=0.001, momentum=0, \
                    decay=0, error="mse", regularization="none", lambda_=0):
        
        epochs_counter = 0
        error_change = sys.maxsize
        previous_error = sys.maxsize

        if not "bias" in x.columns:
            x.insert(0, "bias", np.ones(x.shape[0]))
        
        self.c_values = np.random.rand(x.shape[1])
        
        x_numpy = x.to_numpy()
        
        finish_by_error_dif = False
        errors_list = []
        dCt = np.zeros(x.shape[1])
        
        # Mientras la época (epoch / contador de iteración) no supere el límite o el cambio en el
        # error entre una época y la anterior sea mayor a un umbral:
        while (epochs_counter<max_epochs) and not finish_by_error_dif:

            dCt_previous = dCt
            dCt = self._calculateDF(y, x_numpy, error, self.c_values, self._getRegularizationValue(lambda_, regularization))
            learning_rate = learning_rate/(1+decay)
            self.c_values = self.c_values - learning_rate * (dCt + momentum * dCt_previous)
            y_predict = np.matmul(x_numpy, self.c_values)
            error_change = MSE(y,pd.Series(y_predict, index= y.index)) if error == "mse" else MAE(y,pd.Series(y_predict, index= y.index))
            
            if epochs_counter >= 1 and (previous_error - error_change) < threshold:
                finish_by_error_dif = True
            else:
                previous_error = error_change
                errors_list.append(error_change)
            epochs_counter += 1
        
        # Gráfico para ver el comportamiento del error del modelo por las iteraciones
        len_ = len(errors_list)
        xpoints = np.linspace(0, len_, num = len_)
        plt.plot(xpoints, errors_list)
        plt.xlabel("Epochs")
        plt.ylabel("Error")
        plt.show()

        print('''Error:{}\nIteraciones del algoritmo:{}'''.format(error_change, epochs_counter))
        

    def _calculateDF(self, y_true : pd.Series,  x : np.array,error, c_values : np.array, regularization_value : float):
        '''Método para calcular la derivada del MSE y del MAEde las cj'''
        if error == "mse":
            return 2/y_true.size * (np.transpose(np.matmul(np.transpose(np.matmul(x,c_values) - y_true),x))) + regularization_value
        else:
            # tomado de https://stats.stackexchange.com/questions/312737/mean-absolute-error-mae-derivative
            diferences = (np.matmul(x, c_values ) > y_true)
            values = []
            for value in diferences:
                if value:
                    values.append(1)
                else:
                    values.append(-1)
            return np.array(values).mean() + regularization_value
            
    def _getRegularizationValue(self, lambda_, regularization):
        '''Método para el cálculo de la regularización para la derivada'''
        if regularization == "l1" or regularization == "lasso":
            return lambda_
        elif regularization == "l2" or regularization == "ridge":
            return 2 * lambda_ * self.c_values
        return 0

"""# 5. Utilice el set de datos proveído para probar el funcionamiento de su algoritmo. 
Recuerde que el error debe reducirse en cada iteración del algoritmo (o llegar a un “zig-zag” producto de una tasa de aprendizaje muy elevada). Luego utilice el método train_test_split de la biblioteca sklearn.model_selection para separar un conjunto de datos en un conjunto de datos de entrenamiento y otro de prueba, utilice de semilla del split el número 21 (el método permite el parámetro opcional random_state para sembrar la aleatoriedad).
"""

X_train, X_test, y_train, y_test = train_test_split(df, target_column, test_size=0.3, random_state=21)

linear_regression = LinearRegression()
linear_regression.fit(X_train, y_train,  max_epochs=200000, threshold=1e-3, learning_rate=5e-5, momentum=0.25, \
                    decay=1e-8, error="mse", regularization="l1", lambda_=0.1)

y_predict = linear_regression.predict(X_test)
print("R2:",score(y_test, y_predict))

"""`¿Cuál fue la combinación de parámetros que le proveyó el mejor resultado?`

La combinación de hiperparámetros que mejor resultados me proveyó fue la siguiente:

| Hiperparámetro | Valor |
|--|--|
| max_epochs | 200000 |
| threshold | 1e-3 |
| learning_rate | 5e-5 |
| momentum | 0.25 |
| decay | 1e-8 |
| error | "mse" |
| regularization | "l1" |
| lambda | 0.1 |

Generando un error de 5760.45 y un R<sup>2</sup> de 0.885 en la corrida mostrada. Como se muestra en la gráfica, el error disminuye de forma bastante acentuada en las primeras iteraciones del algoritmo o bien en las primeras épocas, para finalmente decrecer de forma más concervadora, aún así comparando con los valores iniciales, esta medida disminuyó bastante en las 200 000 épocas hasta lograr un R<sup>2</sup> bastante alto lo cual indica que la estimación ha sido bastante certera.

`Prueba con varias semillas`
"""

seeds = np.random.randint(0,100,10)

for seed in seeds:
  print('\nSemilla:',seed)
  X_train, X_test, y_train, y_test = train_test_split(df, target_column, test_size=0.3, random_state=seed)
  linear_regression = LinearRegression()
  linear_regression.fit(X_train, y_train,  max_epochs=200000, threshold=1e-3, learning_rate=5e-5, momentum=0.25, \
                    decay=1e-8, error="mse", regularization="l1", lambda_=0.1)

  y_predict = linear_regression.predict(X_test)
  print('R2:',score(y_test, y_predict))

"""`¿Qué pasa si utiliza esa misma combinación pero cambia la semilla del
train_test_split?`

`Si pasa algo inusual: ¿Por qué cree que pasa esto?`

Como se observa en los gráficos y resultados del R<sup>2</sup>, realmente se obtuvieron muy buenos resultados los cuales se mantienen cercanos a cuando se utilizó la semilla en 21, incluso la mayoría superándo el valor de este último, obteniendo así resultados que van desde el 84% de R<sup>2</sup> el más bajo hasta un 93% de R<sup>2</sup> el más alto. Aún así se puede observar que los valores de error en todos los casos son altos lo cual indica que los resultados no van a ser del todo precisos, sin embargo, como lo muestran los gráficos del comportamiento del error, se nota que este se redujo en bastante medida conforme el algoritmo itera recalculando los pesos del vector C hasta que llega un punto en el que la caída de este disminuye de forma lenta.
"""